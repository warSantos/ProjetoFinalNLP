{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Avaliação de estratégias para melhora de classificação com word embeddings estáticos.\n",
        "\n",
        "Neste notebook apresenta-se a avaliação de diferentes estratégias de enriquecimento de embeddings estáticos para melhorar o desempenho de modelos na classificação de documentos. Neste notebook utilizaremos de recursos comumente utilizados em arquiteturas transformers, mais especificamente Positional Encoding e Self-Attention aplicados em menor escala para verificar o impacto destas estratégias na classificação de documentos. Para tal análise, utilizaremos a base de dados do jornal Folha de São Paulo disponível no link https://www.kaggle.com/marlesson/news-of-the-site-folhauol. Esta base conta com mais de 167 mil documentos e os atributos texto (conteúdo das notícias), title (título da notícia), category (e.g., esporte, colunas, mercado,...), subcategory (e.g., futebol), date (data de publicação) e link para notícia. Destes atributos utilizaremos o conteúdo de texto para produção de vetores densos o atributo category como rótulo para tarefa de classificação. Para construção de vetores densos estáticos utilizaremos o modelo Fasttext."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZcsJKGqz3vew"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import cld3\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import FastText\n",
        "from scipy.special import softmax\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9QUnqes5pEj"
      },
      "source": [
        "# Parâmetros\n",
        "\n",
        "* Para pré processar novamente o texto basta alterar a variável PREPROCESS para True.\n",
        "* Para treinar novamente os modelos cbow e skip-gram basta alterar a variável TRAIN_EMBEDDINGS para True.\n",
        "* Para produzir novas representações vetoriais dos documentos basta alterar a variável MAKE_EMBEDDINGS para True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Yc4i8pul5ovA"
      },
      "outputs": [],
      "source": [
        "PREPROCESS = False\n",
        "TRAIN_EMBEDDINGS = False\n",
        "MAKE_EMBEDDINGS = True\n",
        "BASE_COLS = [\"colunas\", \"cotidiano\", \"esporte\", \"ilustrada\", \"mercado\", \"mundo\", \"poder\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPT_OkK47R4k"
      },
      "source": [
        "# Pré-Processando texto\n",
        "\n",
        "Antes de produzir os vetores densos, aplicamos uma etapa de pré-processamento dos dados, constituída das seguintes sub-etapas: remoção de notícias em lingua não portuguesa, remoção de documentos com menos de 15 palavras, conversão de texto para lowercase, remoção de stop_words e pontuação e tokenização."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QzHdJoZs7NdH"
      },
      "outputs": [],
      "source": [
        "def get_language(text):\n",
        "\n",
        "  return cld3.get_language(text)\n",
        "\n",
        "def get_stop_words():\n",
        "  nltk.download('stopwords')\n",
        "  stop_words = { w:True for w in stopwords.words('portuguese') }\n",
        "  return stop_words\n",
        "\n",
        "def get_tokenizer():\n",
        "  tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
        "  return tokenizer\n",
        "\n",
        "def clean_text(text, tokenizer, stop_words):\n",
        "    tokens = [ word for word in tokenizer.tokenize(text.lower()) if word not in stop_words ]\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "LvB_U6e_77lD"
      },
      "outputs": [],
      "source": [
        "if PREPROCESS:\n",
        "  \n",
        "  data_path = f\"data/articles.csv\"\n",
        "  \n",
        "  # Filtrando colunas do dataset.\n",
        "  df = pd.read_csv(data_path).query(f\"category in {BASE_COLS}\")\n",
        "  df = df[df.text.notna()]\n",
        "  \n",
        "  # Filtrando mensagens que não estão em portugues.\n",
        "  lang_info = df.text.apply(lambda text: get_language(text))\n",
        "  lang = [ d[0] for d in lang_info ]\n",
        "  probs = [ d[1] for d in lang_info ]\n",
        "  df[\"lang\"] = lang\n",
        "  df[\"probs\"] = probs\n",
        "  df = df[df.lang == 'pt']\n",
        "  \n",
        "  # Filtrando stopwords.\n",
        "  tokenizer = get_tokenizer()\n",
        "  stop_words = get_stop_words()\n",
        "  df[\"text_clean\"] = df.text.apply(lambda text: clean_text(text, tokenizer, stop_words))\n",
        "  df.to_csv(f\"data/pt_clean_text.csv\", index=False)\n",
        "\n",
        "  sample = df.sample(frac=0.18, random_state=42)\n",
        "  sample.to_csv(f\"data/pt_sample.csv\", index=False)\n",
        "\n",
        "else:\n",
        "  df = pd.read_csv(f\"data/pt_clean_text.csv\")\n",
        "  sample = pd.read_csv(f\"data/pt_sample.csv\")\n",
        "  sample[\"sent_tokens\"] = sample.text_clean.apply(lambda text: text.split(' '))\n",
        "  sample[\"sent_len\"] = sample.sent_tokens.apply(lambda tokens: len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKnnkn-B30pW"
      },
      "source": [
        "# Treinando/Carregando os modelos de word-embeddings.\n",
        "\n",
        "Para produzir os vetores densos representantes do vocabulário, utilizamos o modelo Fasttext com os parâmetros: dimensão dos vetores (vector_size) 100, tamanho da janela (window) 10, frequência mínima de aparições para palavras (min_count) 3, alpha 0.025 e número de épocas 10. Treinamos dois modelos, um com cbow e outro com skip-gram."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7ov5fonN6km-"
      },
      "outputs": [],
      "source": [
        "def train_model(texts, sg=1):\n",
        "\n",
        "  model = FastText(vector_size=100, window=10, min_count=3, alpha=0.025, min_alpha=0.025, workers=15, sg=sg)\n",
        "  model.build_vocab(texts)\n",
        "  for epoch in tqdm(range(10)):\n",
        "    model.train(texts, total_examples=model.corpus_count, epochs=1)\n",
        "    model.alpha -= 0.002\n",
        "    model.min_alpha = model.alpha\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Z9mn1tMa9f9d"
      },
      "outputs": [],
      "source": [
        "if TRAIN_EMBEDDINGS:\n",
        "  df = pd.read_csv(f\"data/pt_clean_text.csv\")\n",
        "  cbow_model = train_model(df.sent_tokens.values, sg=0)\n",
        "  skip_model = train_model(df.sent_tokens.values, sg=1)\n",
        "  cbow_model.save(f\"models/fasttext_cbow\")\n",
        "  skip_model.save(f\"models/fasttext_sg\")\n",
        "else:\n",
        "  cbow_model = FastText.load(\"models/fasttext_cbow\")\n",
        "  skip_model = FastText.load(\"models/fasttext_sg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGikWX8g4A8r"
      },
      "source": [
        "### Estatísticas dos documentos. Tamanho máximo, mínimo, médio e desvio padrão do tamanho dos documentos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "gg3ai6ja4Xqx",
        "outputId": "f47202a4-2ca4-4271-f8c6-bf009ab3546e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">sent_len</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>max</th>\n",
              "      <th>min</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>colunas</th>\n",
              "      <td>1567</td>\n",
              "      <td>2</td>\n",
              "      <td>275.517763</td>\n",
              "      <td>133.992314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cotidiano</th>\n",
              "      <td>1237</td>\n",
              "      <td>16</td>\n",
              "      <td>256.950916</td>\n",
              "      <td>159.574418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>esporte</th>\n",
              "      <td>1665</td>\n",
              "      <td>22</td>\n",
              "      <td>216.727247</td>\n",
              "      <td>143.771406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ilustrada</th>\n",
              "      <td>3886</td>\n",
              "      <td>16</td>\n",
              "      <td>249.976336</td>\n",
              "      <td>185.272439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mercado</th>\n",
              "      <td>6467</td>\n",
              "      <td>8</td>\n",
              "      <td>276.115907</td>\n",
              "      <td>204.021483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mundo</th>\n",
              "      <td>2249</td>\n",
              "      <td>25</td>\n",
              "      <td>281.860541</td>\n",
              "      <td>181.532158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poder</th>\n",
              "      <td>2905</td>\n",
              "      <td>14</td>\n",
              "      <td>280.942387</td>\n",
              "      <td>178.767552</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          sent_len                            \n",
              "               max min        mean         std\n",
              "category                                      \n",
              "colunas       1567   2  275.517763  133.992314\n",
              "cotidiano     1237  16  256.950916  159.574418\n",
              "esporte       1665  22  216.727247  143.771406\n",
              "ilustrada     3886  16  249.976336  185.272439\n",
              "mercado       6467   8  276.115907  204.021483\n",
              "mundo         2249  25  281.860541  181.532158\n",
              "poder         2905  14  280.942387  178.767552"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample.groupby(\"category\").agg({\"sent_len\": [\"max\", \"min\", \"mean\", \"std\"]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Os documentos não possuem padrão bem definido em relação a quantidade de tokens para qualquer uma das categorias, como podemos ver, para todas as categorias temos um elevado desvio (acima de 140 para todas as categorias) padrão na quantidade de tokens médio dos documentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLEDAeF84cMM"
      },
      "source": [
        "### Removendo documentos com menos de 15 palavras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1C85uwxs4gIS"
      },
      "outputs": [],
      "source": [
        "sample = sample[sample.sent_len > 15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WChmYN4i4klA"
      },
      "source": [
        "### Distribuição de documentos pelas classes.\n",
        "\n",
        "Como mostrado no gráfico abaixo, as classes estão bem balanceadas, nenuma das classes possui o dobro dos documentos a outra."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "uOq3izhS4kVq",
        "outputId": "d7598210-abc3-46c9-9ae1-b12ac44dadff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "sample.category.value_counts().plot(kind='bar', grid=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4_GBZBZ4oz6"
      },
      "source": [
        "### Obtendo TF-IDF das palavras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf = TfidfVectorizer(min_df=3)\n",
        "_ = tf.fit_transform(df.text_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.88it/s]\n",
            "/tmp/ipykernel_909794/3983148088.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  tfidf_matrix = np.array([ get_tfidf_norm(sent, cbow_model, tf) for sent in tqdm(sample.sent_tokens.values[:10]) ])\n"
          ]
        }
      ],
      "source": [
        "def get_tfidf_norm(sent, cbow_model, tfidf):\n",
        "    x = np.array([ tfidf.idf_[tfidf.vocabulary_[token]] for token in sent if token in tfidf.vocabulary_ and token in cbow_model.wv ])\n",
        "    #x = x / np.max(x)\n",
        "    return x\n",
        "if MAKE_EMBEDDINGS:\n",
        "    tfidf_matrix = np.array([ get_tfidf_norm(sent, cbow_model, tf) for sent in tqdm(sample.sent_tokens.values) ])\n",
        "    np.save(\"embeddings/tfidf_scores.npy\", tfidf_matrix, allow_pickle=True)\n",
        "else:\n",
        "    tfidf_matrix = np.load(\"embeddings/tfidf_scores.npy\", allow_pickle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6Sany774udw"
      },
      "source": [
        "### Funções para gerar as representações vetoriais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aUH850Hh4uAp"
      },
      "outputs": [],
      "source": [
        "def get_positional_embs(n_words=5559, dim=200):\n",
        "\n",
        "    return np.vstack([positional_vector(i, dim=dim) for i in range(n_words)])\n",
        "\n",
        "\n",
        "def positional_vector(pos, dim=100, denom=10000):\n",
        "\n",
        "    pos_values = []\n",
        "    for i in range(dim):\n",
        "        pw = 2 * i\n",
        "        if i % 2 == 0:\n",
        "            res = np.sin(pos / np.power(denom, pw/dim))\n",
        "        else:\n",
        "            res = np.cos(pos / np.power(denom, pw/dim))\n",
        "        pos_values.append(res)\n",
        "    return np.array(pos_values)\n",
        "\n",
        "\n",
        "def check_word(word, cbow_model, skip_model, tf=None):\n",
        "\n",
        "    # Se a palavra estiver no cbow e no skipgram.\n",
        "    if word in cbow_model.wv and word in skip_model.wv:\n",
        "        # Se não estiver usando IDF.\n",
        "        if tf is None:\n",
        "            return True\n",
        "        else:\n",
        "            # Se a palavra estiver no vocabulário IDF.\n",
        "            if word in tf.vocabulary_:\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def tokens_to_embs(sent_tokens, cbow, skip, option=1, pos_embs=None, idf=None, tf=None):\n",
        "\n",
        "    if option not in [1, 2, 3]:\n",
        "        option = 2\n",
        "\n",
        "    # Cbow somente\n",
        "    if option == 1:\n",
        "        words_vec = np.vstack([cbow.wv[token] for token in sent_tokens if check_word(\n",
        "            token, cbow_model, skip_model, tf)])\n",
        "    # Skip Gram\n",
        "    elif option == 2:\n",
        "        words_vec = np.vstack([cbow.wv[token] for token in sent_tokens if check_word(\n",
        "            token, cbow_model, skip_model, tf)])\n",
        "    # Skip e Cbow Combinados.\n",
        "    elif option == 3:\n",
        "        words_vec = np.vstack([np.hstack([cbow.wv[token], skip.wv[token]])\n",
        "                              for token in sent_tokens if check_word(token, cbow_model, skip_model, tf)])\n",
        "\n",
        "    if pos_embs is not None:\n",
        "        words_vec += pos_embs[:words_vec.shape[0], :words_vec.shape[1]]\n",
        "        return words_vec\n",
        "    if idf is not None:\n",
        "        return (words_vec.T * idf).T\n",
        "    return words_vec\n",
        "\n",
        "\n",
        "def get_raw_embs(sentences_tokes, cbow, skip, option=1, pos_embs=None, tfidf_matrix=None, tf=None):\n",
        "\n",
        "    if tfidf_matrix is None:\n",
        "        return np.vstack([np.mean(tokens_to_embs(sent_tokens, cbow, skip, option=option, pos_embs=pos_embs, tf=tf), axis=0) for sent_tokens in sentences_tokes])\n",
        "    else:\n",
        "        return np.vstack([np.mean(tokens_to_embs(sent_tokens, cbow, skip, option=option, pos_embs=pos_embs, idf=widf, tf=tf), axis=0) for sent_tokens, widf in zip(sentences_tokes, tfidf_matrix)])\n",
        "\n",
        "\n",
        "def attention_eval(embs, norm=\"softmax\", att_type=\"product\"):\n",
        "\n",
        "    if att_type == \"product\":\n",
        "        w = softmax(np.inner(embs, embs), axis=1)\n",
        "    else:\n",
        "        w = cosine_similarity(embs, embs)\n",
        "\n",
        "    context_words = np.dot(w, embs)\n",
        "\n",
        "    if norm == \"mean\":\n",
        "        return np.mean(context_words, axis=0)\n",
        "    else:\n",
        "        return softmax(np.sum(context_words, axis=0), axis=0)\n",
        "\n",
        "\n",
        "def attention(sentences_tokes, cbow, skip, option=1, norm=\"mean\", pos_embs=None, tfidf_matrix=None, tf=None, att_type=\"product\"):\n",
        "\n",
        "    if tfidf_matrix is None:\n",
        "        return np.array([attention_eval(tokens_to_embs(sent_tokens, cbow, skip, option=option, pos_embs=pos_embs, tf=tf), att_type=att_type) for sent_tokens in sentences_tokes])\n",
        "    else:\n",
        "        return np.array([attention_eval(tokens_to_embs(sent_tokens, cbow, skip, option=option, pos_embs=pos_embs, idf=widf, tf=tf), att_type=att_type) for sent_tokens, widf in zip(sentences_tokes, tfidf_matrix)])\n",
        "\n",
        "\n",
        "def save_embs(dict_embs, embs_dir):\n",
        "\n",
        "    for emb in dict_embs:\n",
        "        np.save(f\"{embs_dir}/{emb}.npy\", dict_embs[emb], allow_pickle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoFXymg34zMt"
      },
      "source": [
        "### Cross-Validation pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RemI_Rnk42ej"
      },
      "outputs": [],
      "source": [
        "def evaluate(dict_embs, y_true, dict_scores, kf):\n",
        "\n",
        "    for key_emb in dict_embs:\n",
        "        print(f\"Embedding: {key_emb}\")\n",
        "        dict_scores[key_emb] = {}\n",
        "        fold = 0\n",
        "        # Para cada fold.\n",
        "        for train_idx, test_idx in tqdm(kf.split(dict_embs[key_emb], y_true)):\n",
        "            print(f\"\\tFold: {fold}\")\n",
        "            # Para cada classificador.\n",
        "            for key_clf in dict_clfs:\n",
        "                #print(f\"\\t\\tClassifier: {key_clf}\")\n",
        "                dict_clfs[key_clf].fit(dict_embs[key_emb][train_idx], y_true[train_idx])\n",
        "                y_pred = dict_clfs[key_clf].predict(dict_embs[key_emb][test_idx])\n",
        "                if key_clf not in dict_scores[key_emb]:\n",
        "                    dict_scores[key_emb][key_clf] = {}\n",
        "                # Calculando métricas.\n",
        "                if \"micro\" not in dict_scores[key_emb][key_clf]:\n",
        "                    dict_scores[key_emb][key_clf][\"micro\"] = []\n",
        "                dict_scores[key_emb][key_clf][\"micro\"].append(f1_score(y_true[test_idx], y_pred, average=\"micro\"))\n",
        "                if \"macro\" not in dict_scores[key_emb][key_clf]:\n",
        "                    dict_scores[key_emb][key_clf][\"macro\"] = []\n",
        "                dict_scores[key_emb][key_clf][\"macro\"].append(f1_score(y_true[test_idx], y_pred, average=\"macro\"))\n",
        "                if \"precision\" not in dict_scores[key_emb][key_clf]:\n",
        "                    dict_scores[key_emb][key_clf][\"precision\"] = []\n",
        "                dict_scores[key_emb][key_clf][\"precision\"].append(precision_score(y_true[test_idx], y_pred, average=\"macro\"))\n",
        "                if \"recall\" not in dict_scores[key_emb][key_clf]:\n",
        "                    dict_scores[key_emb][key_clf][\"recall\"] = []\n",
        "                dict_scores[key_emb][key_clf][\"recall\"].append(recall_score(y_true[test_idx], y_pred, average=\"macro\"))\n",
        "            fold += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KaNK7jQ49nR"
      },
      "source": [
        "# Generating Baseline Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQCOs-hy471d"
      },
      "outputs": [],
      "source": [
        "dict_embs = {}\n",
        "if MAKE_EMBEDDINGS:\n",
        "    dict_embs[\"cbow\"] = get_raw_embs(sample.sent_tokens.values, cbow_model, skip_model, option=1)\n",
        "    dict_embs[\"skip\"] = get_raw_embs(sample.sent_tokens.values, cbow_model, skip_model, option=2)\n",
        "    dict_embs[\"cbow_skip\"] = get_raw_embs(sample.sent_tokens.values, cbow_model, skip_model, option=3)\n",
        "    dict_embs[\"cbow-tf-idf\"] = get_raw_embs(sample.sent_tokens.values, cbow_model, skip_model, option=1, tfidf_matrix=tfidf_matrix, tf=tf)\n",
        "    dict_embs[\"skip-tf-idf\"] = get_raw_embs(sample.sent_tokens.values, cbow_model, skip_model, option=2, tfidf_matrix=tfidf_matrix, tf=tf)\n",
        "    dict_embs[\"cbow_skip-tf-idf\"] = get_raw_embs(sample.sent_tokens.values, cbow_model, skip_model, option=3, tfidf_matrix=tfidf_matrix, tf=tf)\n",
        "    save_embs(dict_embs, \"embeddings\")\n",
        "else:\n",
        "    dict_embs[\"cbow\"] = np.load(\"embeddings/cbow.npy\")\n",
        "    dict_embs[\"skip\"] = np.load(\"embeddings/skip.npy\")\n",
        "    dict_embs[\"cbow_skip\"] = np.load(\"embeddings/cbow_skip.npy\")\n",
        "    dict_embs[\"cbow-tf-idf\"] = np.load(\"embeddings/cbow-tf-idf.npy\")\n",
        "    dict_embs[\"skip-tf-idf\"] = np.load(\"embeddings/skip-tf-idf.npy\")\n",
        "    dict_embs[\"cbow_skip-tf-idf\"] = np.load(\"embeddings/cbow_skip-tf-idf.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w86SWl_Q5C24"
      },
      "source": [
        "# Avaliação da baseline\n",
        "\n",
        "Neste trabalho utilizaremos como baseline para as avaliações aqui feitas as seguintes representações: Fasttext-Cbow, Fasttext-Skip-Gram e Cbow-Skip-Gram (concatenação dos vetores duas estratégias)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmnBmAcD5CbH"
      },
      "outputs": [],
      "source": [
        "dict_clfs = {}\n",
        "dict_clfs[\"LogisticRegression\"] = LogisticRegression(max_iter=5000, n_jobs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9-k1rwH5HCg"
      },
      "outputs": [],
      "source": [
        "dict_scores = {}\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(sample.category.values)\n",
        "y_true = le.transform(sample.category.values)\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(dict_embs, y_true, dict_scores, kf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkSNfBr25MlY"
      },
      "outputs": [],
      "source": [
        "table = []\n",
        "for emb in dict_scores:\n",
        "    for clf in dict_scores[emb]:\n",
        "        table.append([emb, np.mean(dict_scores[emb][clf][\"macro\"]), np.std(dict_scores[emb][clf][\"macro\"])])\n",
        "pd.DataFrame(table, columns=[\"Embedding\", \"F1-Macro (Mean)\", \"Std\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelos propostos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pos_embs = get_positional_embs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_909794/426955937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mMAKE_EMBEDDINGS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Product Attention.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdict_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cbow_skip-product\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdict_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cbow_skip-product-positional\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdict_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cbow_skip-tf-idf-product\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_909794/3662986676.py\u001b[0m in \u001b[0;36mattention\u001b[0;34m(sentences_tokes, cbow, skip, option, norm, pos_embs, tfidf_matrix, tf, att_type)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtfidf_matrix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattention_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_to_embs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_embs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matt_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent_tokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences_tokes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattention_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_to_embs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_embs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matt_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_tokes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_909794/3662986676.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtfidf_matrix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattention_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_to_embs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_embs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matt_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent_tokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences_tokes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattention_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens_to_embs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_embs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_embs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matt_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences_tokes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfidf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_909794/3662986676.py\u001b[0m in \u001b[0;36mtokens_to_embs\u001b[0;34m(sent_tokens, cbow, skip, option, pos_embs, idf, tf)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# Skip e Cbow Combinados.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moption\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         words_vec = np.vstack([np.hstack([cbow.wv[token], skip.wv[token]])\n\u001b[0m\u001b[1;32m     49\u001b[0m                               for token in sent_tokens if check_word(token, cbow_model, skip_model, tf)])\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_909794/3662986676.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0moption\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         words_vec = np.vstack([np.hstack([cbow.wv[token], skip.wv[token]])\n\u001b[0;32m---> 49\u001b[0;31m                               for token in sent_tokens if check_word(token, cbow_model, skip_model, tf)])\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpos_embs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "dict_embs = {}\n",
        "if MAKE_EMBEDDINGS:\n",
        "    # Product Attention.\n",
        "    dict_embs[\"cbow_skip-product\"] = attention(sample.sent_tokens.values, cbow_model, skip_model, option=3)\n",
        "    dict_embs[\"cbow_skip-product-positional\"] = attention(sample.sent_tokens.values, cbow_model, skip_model, option=3)\n",
        "    dict_embs[\"cbow_skip-tf-idf-product\"] = attention(sample.sent_tokens.values, cbow_model, skip_model, option=3, tfidf_matrix=tfidf_matrix)\n",
        "    dict_embs[\"cbow_skip-tf-idf-product-positional\"] = attention(sample.sent_tokens.values, cbow_model, skip_model, option=3, pos_embs=pos_embs, tfidf_matrix=tfidf_matrix)\n",
        "    \n",
        "    # Consine Attention\n",
        "    dict_embs[\"cbow_skip-consise\"] = attention(sample.sent_tokens.values, cbow_model, skip_model, option=3, att_type=\"cosine\")\n",
        "    dict_embs[\"cbow_skip-consise-positional\"] = attention(sample.sent_tokens.values, cbow_model, skip_model, option=3, att_type=\"cosine\")\n",
        "    dict_embs[\"cbow_skip-tf-idf-consise\"] = attention(sample.sent_tokens.values, cbow_model, skip_model, option=3, tfidf_matrix=tfidf_matrix, att_type=\"cosine\")\n",
        "    dict_embs[\"cbow_skip-tf-idf-consise-positional\"] = attention(sample.sent_tokens.values, cbow_model, skip_model, option=3, pos_embs=pos_embs, tfidf_matrix=tfidf_matrix, att_type=\"cosine\")\n",
        "\n",
        "    save_embs(dict_embs, \"embeddings\")\n",
        "else:\n",
        "    dict_embs[\"cbow_skip-product\"] = np.load(\"embeddings/cbow_skip-product.npy\")\n",
        "    dict_embs[\"cbow_skip-product-positional\"] = np.load(\"embeddings/cbow_skip-product-positional.npy\")\n",
        "    dict_embs[\"cbow_skip-tf-idf-product\"] = np.load(\"embeddings/cbow_skip-tf-idf-product.npy\")\n",
        "    dict_embs[\"cbow_skip-tf-idf-product-positional\"] = np.load(\"embeddings/cbow_skip-tf-idf-product-positional.npy\")\n",
        "\n",
        "    dict_embs[\"cbow_skip-consise\"] = np.load(\"embeddings/cbow_skip-consise.npy\")\n",
        "    dict_embs[\"cbow_skip-consise-positional\"] = np.load(\"embeddings/cbow_skip-consise-positional.npy\")\n",
        "    dict_embs[\"cbow_skip-tf-idf-consise\"] = np.load(\"embeddings/cbow_skip-tf-idf-consise.npy\")\n",
        "    dict_embs[\"cbow_skip-tf-idf-consise-positional\"] = np.load(\"embeddings/cbow_skip-tf-idf-consise-positional.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate(dict_embs, y_true, dict_scores, kf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"outputs/scores_idf.json\",\"w\") as fd:\n",
        "    json.dump(dict_scores, fd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7wunAZP5S3R"
      },
      "source": [
        "### Positional Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9qZSVvA5SIJ"
      },
      "outputs": [],
      "source": [
        "if MAKE_EMBEDDINGS:\n",
        "    dict_embs[\"cbow_postitional\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=1, pos_embs=pos_embs, tfidf_matrix=tfidf_matrix)\n",
        "    dict_embs[\"skip_postitional\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=2, pos_embs=pos_embs, tfidf_matrix=tfidf_matrix)\n",
        "    dict_embs[\"cbow_skip_postitional\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=3, pos_embs=pos_embs, tfidf_matrix=tfidf_matrix)\n",
        "    save_embs(dict_embs, \"embeddings\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HeatMaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "EvaluationModels.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
