{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from gensim.models import FastText\n",
    "from scipy.special import softmax\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinando/Carregando os modelos de word-embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbow_model = FastText.load(\"models/fasttext_cbow\")\n",
    "skip_model = FastText.load(\"models/fasttext_sg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando dataset para avaliação dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_850313/2335971799.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/pt_sample_clean_articles.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/NLP/.env/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NLP/.env/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NLP/.env/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NLP/.env/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NLP/.env/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/NLP/.env/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/NLP/.env/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/NLP/.env/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/NLP/.env/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "sample = pd.read_csv(\"data/pt_sample_clean_articles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estatísticas dos documentos. Tamanho máximo, mínimo, médio e desvio padrão do tamanho dos documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">sentence_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>colunas</th>\n",
       "      <td>5559</td>\n",
       "      <td>2</td>\n",
       "      <td>281.152033</td>\n",
       "      <td>158.692644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cotidiano</th>\n",
       "      <td>1710</td>\n",
       "      <td>16</td>\n",
       "      <td>252.123818</td>\n",
       "      <td>158.454574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esporte</th>\n",
       "      <td>2324</td>\n",
       "      <td>20</td>\n",
       "      <td>212.740087</td>\n",
       "      <td>141.340121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ilustrada</th>\n",
       "      <td>2237</td>\n",
       "      <td>16</td>\n",
       "      <td>244.453350</td>\n",
       "      <td>171.822922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercado</th>\n",
       "      <td>4879</td>\n",
       "      <td>14</td>\n",
       "      <td>277.700649</td>\n",
       "      <td>183.226186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mundo</th>\n",
       "      <td>2269</td>\n",
       "      <td>19</td>\n",
       "      <td>272.711735</td>\n",
       "      <td>175.751087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poder</th>\n",
       "      <td>2580</td>\n",
       "      <td>14</td>\n",
       "      <td>279.250114</td>\n",
       "      <td>177.560919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentence_len                            \n",
       "                   max min        mean         std\n",
       "category                                          \n",
       "colunas           5559   2  281.152033  158.692644\n",
       "cotidiano         1710  16  252.123818  158.454574\n",
       "esporte           2324  20  212.740087  141.340121\n",
       "ilustrada         2237  16  244.453350  171.822922\n",
       "mercado           4879  14  277.700649  183.226186\n",
       "mundo             2269  19  272.711735  175.751087\n",
       "poder             2580  14  279.250114  177.560919"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"sentence_tokens\"] = sample.text_clean.apply(lambda text: text.split(' '))\n",
    "sample[\"sentence_len\"] = sample.sentence_tokens.apply(lambda tokens: len(tokens))\n",
    "sample.groupby(\"category\").agg({\"sentence_len\": [\"max\", \"min\", \"mean\", \"std\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo documentos com menos de 15 palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample[sample.sentence_len > 14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição de documentos pelas classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample.category.value_counts().plot(kind='bar', grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo TF-IDF das palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(min_df=3)\n",
    "tf.fit_transform(sample.text_clean)\n",
    "tfidf_matrix = [ np.mean(np.array([ tf.vocabulary_[token] for token in sent if token in tf.vocabulary_ ]), axis=0) for sent in sample.sentence_tokens ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para gerar as representações vetoriais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embs(n_words=5559, dim=200):\n",
    "\n",
    "    return np.vstack([ positional_vector(i, dim=dim) for i in range(n_words) ])\n",
    "\n",
    "def positional_vector(pos, dim=100, denom=10000):\n",
    "\n",
    "    pos_values = []\n",
    "    for i in range(dim):\n",
    "        pw = 2 * i\n",
    "        if i % 2 == 0:\n",
    "            res = np.sin(pos / np.power(denom, pw/dim))\n",
    "        else:\n",
    "            res = np.cos(pos / np.power(denom, pw/dim))\n",
    "        pos_values.append(res)\n",
    "    return np.array(pos_values)\n",
    "\n",
    "def tokens_to_embs(sent_tokens, cbow, skip, option=1, pos_embs=None, idf=None):\n",
    "\n",
    "    if option not in [1,2,3]:\n",
    "        option = 2\n",
    "\n",
    "    # Cbow somente\n",
    "    if option == 1:\n",
    "        words_vec = np.vstack([ cbow.wv[token] for token in sent_tokens if token in cbow.wv ])\n",
    "    # Skip Gram\n",
    "    elif option == 2:\n",
    "        words_vec = np.vstack([ cbow.wv[token] for token in sent_tokens if token in cbow.wv ])\n",
    "    # Skip e Cbow Combinados.\n",
    "    elif option == 3:\n",
    "        words_vec = np.vstack([ np.hstack([cbow.wv[token], skip.wv[token]]) for token in sent_tokens if token in cbow.wv ])\n",
    "    \n",
    "    if pos_embs is not None:\n",
    "        words_vec += pos_embs[:words_vec.shape[0], :words_vec.shape[1]]\n",
    "        return words_vec\n",
    "    if idf is not None:\n",
    "        return (words_vec.T * idf).T\n",
    "    return words_vec\n",
    "\n",
    "def get_raw_embs(sentences_tokes, cbow, skip, option=1, pos_embs=None, tfidf_matrix=None):\n",
    "\n",
    "    if tfidf_matrix is None:\n",
    "        return np.vstack([ np.mean(tokens_to_embs(sent_tokens, cbow, skip, option=option, pos_embs=pos_embs), axis=0) for sent_tokens in tqdm(sentences_tokes) ])\n",
    "    else:\n",
    "        return np.vstack([ np.mean(tokens_to_embs(sent_tokens, cbow, skip, option=option, pos_embs=pos_embs, idf=widf), axis=0) for sent_tokens, widf in tqdm(zip(sentences_tokes, tfidf_matrix)) ])\n",
    "\n",
    "def attention_eval(embs, w_idf=None, norm=\"mean\"):\n",
    "\n",
    "    w = softmax(np.inner(embs, embs), axis=1)\n",
    "    context_words = np.dot(w, embs)\n",
    "    if norm == \"mean\":\n",
    "        return np.mean(context_words, axis=0)\n",
    "    else:\n",
    "        return softmax(np.sum(context_words, axis=0), axis=0)\n",
    "\n",
    "def attention(sentences_tokes, cbow, skip, option=1, norm=\"mean\", pos_embs=None):\n",
    "\n",
    "    return np.array([ attention_eval(tokens_to_embs(sent_tokens, cbow, skip, option=option, pos_embs=pos_embs)) for sent_tokens in tqdm(sentences_tokes) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(dict_embs, y_true, dict_scores):\n",
    "\n",
    "    for key_emb in tqdm(dict_embs):\n",
    "        print(f\"Embedding: {key_emb}\")\n",
    "        dict_scores[key_emb] = {}\n",
    "        fold = 0\n",
    "        # Para cada fold.\n",
    "        for train_idx, test_idx in kf.split(dict_embs[key_emb], y_true):\n",
    "            print(f\"\\tFold: {fold}\")\n",
    "            # Para cada classificador.\n",
    "            for key_clf in dict_clfs:\n",
    "                print(f\"\\t\\tClassifier: {key_clf}\")\n",
    "                dict_clfs[key_clf].fit(dict_embs[key_emb][train_idx], y_true[train_idx])\n",
    "                y_pred = dict_clfs[key_clf].predict(dict_embs[key_emb][test_idx])\n",
    "                if key_clf not in dict_scores[key_emb]:\n",
    "                    dict_scores[key_emb][key_clf] = {}\n",
    "                # Calculando métricas.\n",
    "                if \"micro\" not in dict_scores[key_emb][key_clf]:\n",
    "                    dict_scores[key_emb][key_clf][\"micro\"] = []\n",
    "                dict_scores[key_emb][key_clf][\"micro\"].append(f1_score(y_true[test_idx], y_pred, average=\"micro\"))\n",
    "                if \"macro\" not in dict_scores[key_emb][key_clf]:\n",
    "                    dict_scores[key_emb][key_clf][\"macro\"] = []\n",
    "                dict_scores[key_emb][key_clf][\"macro\"].append(f1_score(y_true[test_idx], y_pred, average=\"macro\"))\n",
    "                if \"precision\" not in dict_scores[key_emb][key_clf]:\n",
    "                    dict_scores[key_emb][key_clf][\"precision\"] = []\n",
    "                dict_scores[key_emb][key_clf][\"precision\"].append(precision_score(y_true[test_idx], y_pred, average=\"macro\"))\n",
    "                if \"recall\" not in dict_scores[key_emb][key_clf]:\n",
    "                    dict_scores[key_emb][key_clf][\"recall\"] = []\n",
    "                dict_scores[key_emb][key_clf][\"recall\"].append(recall_score(y_true[test_idx], y_pred, average=\"macro\"))\n",
    "        fold += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Baseline embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26634/26634 [00:26<00:00, 991.96it/s] \n",
      "100%|██████████| 26634/26634 [00:26<00:00, 1022.24it/s]\n",
      "100%|██████████| 26634/26634 [01:19<00:00, 337.07it/s]\n",
      "26634it [00:30, 884.63it/s]\n",
      "26634it [00:29, 890.12it/s]\n",
      "26634it [01:20, 330.27it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_embs = {}\n",
    "dict_embs[\"cbow\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=1)\n",
    "dict_embs[\"skip\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=2)\n",
    "dict_embs[\"cbow_skip\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=3)\n",
    "dict_embs[\"cbow-tf-idf\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=1, tfidf_matrix=tfidf_matrix)\n",
    "dict_embs[\"skip-tf-idf\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=2, tfidf_matrix=tfidf_matrix)\n",
    "dict_embs[\"cbow_skip-tf-idf\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=3, tfidf_matrix=tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_clfs = {}\n",
    "dict_clfs[\"LogisticRegression\"] = LogisticRegression(max_iter=5000, n_jobs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_scores = {}\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(sample.category.values)\n",
    "y_true = le.transform(sample.category.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow 0.8324251153959921 0.0023846018934665547\n",
      "cbow_postitional 0.831711750812502 0.0025079873158895603\n",
      "skip 0.8324251153959921 0.0023846018934665547\n",
      "skip_postitional 0.831711750812502 0.0025079873158895603\n",
      "cbow_skip 0.8392559227186147 0.002614862039181853\n",
      "cbow_skip_postitional 0.8440224629809521 0.004451939391685543\n"
     ]
    }
   ],
   "source": [
    "for emb in dict_scores:\n",
    "    for clf in dict_scores[emb]:\n",
    "        print(emb, np.mean(dict_scores[emb][clf][\"macro\"]), np.std(dict_scores[emb][clf][\"macro\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/scores_idf.json\",\"w\") as fd:\n",
    "    json.dump(dict_scores, fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embs = get_positional_embs()\n",
    "dict_embs[\"cbow_postitional\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=1, pos_embs=pos_embs, tfidf_matrix=tfidf_matrix)\n",
    "dict_embs[\"skip_postitional\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=2, pos_embs=pos_embs, tfidf_matrix=tfidf_matrix)\n",
    "dict_embs[\"cbow_skip_postitional\"] = get_raw_embs(sample.sentence_tokens.values, cbow_model, skip_model, option=3, pos_embs=pos_embs, tfidf_matrix=tfidf_matrix)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40c67870e10c50d8972c13f109a0fc0444936a2c7a1b7f5ddf7e0141969deeb7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
